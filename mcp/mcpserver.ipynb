{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a73eb797-2ec2-476e-84ee-6ec6b77bcfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is E25B-F2F8\n",
      "\n",
      " Directory of C:\\Users\\LENOVO\\servermcp\n",
      "\n",
      "17-08-2025  09:56    <DIR>          .\n",
      "17-08-2025  09:56    <DIR>          ..\n",
      "17-08-2025  09:55               109 .gitignore\n",
      "17-08-2025  09:54    <DIR>          .ipynb_checkpoints\n",
      "17-08-2025  09:55                 5 .python-version\n",
      "17-08-2025  09:56    <DIR>          .venv\n",
      "17-08-2025  09:55                87 main.py\n",
      "17-08-2025  09:56               195 pyproject.toml\n",
      "17-08-2025  09:55                 0 README.md\n",
      "17-08-2025  09:54               337 server.ipynb\n",
      "17-08-2025  09:56            93,235 uv.lock\n",
      "               7 File(s)         93,968 bytes\n",
      "               4 Dir(s)  12,254,175,232 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "392ebc5e-9493-4cbf-bd7c-d7a6cb5c44b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting C:\\Users\\LENOVO\\servermcp/research_server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile C:\\Users\\LENOVO\\servermcp/research_server.py\n",
    "\n",
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from typing import List\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "\n",
    "PAPER_DIR = \"papers\"\n",
    "\n",
    "# Initialize FastMCP server\n",
    "mcp = FastMCP(\"research\")\n",
    "\n",
    "@mcp.tool()\n",
    "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for papers on arXiv based on a topic and store their information.\n",
    "    \n",
    "    Args:\n",
    "        topic: The topic to search for\n",
    "        max_results: Maximum number of results to retrieve (default: 5)\n",
    "        \n",
    "    Returns:\n",
    "        List of paper IDs found in the search\n",
    "    \"\"\"\n",
    "    \n",
    "    # DEFENSIVE: Clean and sanitize the topic input\n",
    "    if not isinstance(topic, str):\n",
    "        topic = str(topic)\n",
    "    \n",
    "    # Remove control characters and clean whitespace\n",
    "    topic = ''.join(char for char in topic if ord(char) >= 32 and char not in '<>:\"/\\\\|?*')\n",
    "    topic = topic.strip()\n",
    "    \n",
    "    # Validate that we have a real topic\n",
    "    if not topic:\n",
    "        raise ValueError(\"Topic cannot be empty\")\n",
    "    \n",
    "    # Use arxiv to find the papers \n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Search for the most relevant articles matching the queried topic\n",
    "    search = arxiv.Search(\n",
    "        query = topic,\n",
    "        max_results = max_results,\n",
    "        sort_by = arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    papers = client.results(search)\n",
    "    \n",
    "    # Create directory for this topic - SANITIZED\n",
    "    safe_topic = re.sub(r'[<>:\"/\\\\|?*\\x00-\\x1F]', '_', topic.lower())\n",
    "    safe_topic = re.sub(r'_+', '_', safe_topic)  # Replace multiple underscores\n",
    "    safe_topic = safe_topic.strip('_')  # Remove leading/trailing underscores\n",
    "    \n",
    "    # Handle empty topic name edge case\n",
    "    if not safe_topic:\n",
    "        safe_topic = \"untitled\"\n",
    "    \n",
    "    path = os.path.join(PAPER_DIR, safe_topic)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "    # Try to load existing papers info\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    # Process each paper and add to papers_info  \n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            'title': paper.title,\n",
    "            'authors': [author.name for author in paper.authors],\n",
    "            'summary': paper.summary,\n",
    "            'pdf_url': paper.pdf_url,\n",
    "            'published': str(paper.published.date())\n",
    "        }\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "    \n",
    "    # Save updated papers_info to json file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(papers_info, json_file, indent=2)\n",
    "    \n",
    "    print(f\"Results are saved in: {file_path}\")\n",
    "    \n",
    "    return paper_ids\n",
    "\n",
    "@mcp.tool()\n",
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information about a specific paper across all topic directories.\n",
    "    \n",
    "    Args:\n",
    "        paper_id: The ID of the paper to look for\n",
    "        \n",
    "    Returns:\n",
    "        JSON string with paper information if found, error message if not found\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate paper_id\n",
    "    if not paper_id or not isinstance(paper_id, str):\n",
    "        return \"Invalid paper ID provided\"\n",
    "    \n",
    "    # Clean paper_id\n",
    "    paper_id = paper_id.strip()\n",
    "    \n",
    "    # Check if papers directory exists\n",
    "    if not os.path.exists(PAPER_DIR):\n",
    "        return f\"No papers directory found. Please run a search first.\"\n",
    "    \n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    return f\"There's no saved information related to paper {paper_id}.\"\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize and run the server\n",
    "    mcp.run(transport='stdio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556b7b10-1e3c-4d64-b559-6bcfdfd8828c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
